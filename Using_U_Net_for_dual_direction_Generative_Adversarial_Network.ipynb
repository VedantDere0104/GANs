{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Using_U_Net for_dual_direction_Generative_Adversarial_Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1c_x2xy4PN14h5T2DF-bK2wd-ZcfL-6Cl",
      "authorship_tag": "ABX9TyNm63Z7vp9uu6yeNZFRDOyL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VedantDere0104/GANs/blob/main/Using_U_Net_for_dual_direction_Generative_Adversarial_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dn2jwrGqtRpY"
      },
      "source": [
        "####"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2aw80bH8AQod"
      },
      "source": [
        "import torch\r\n",
        "from torch import nn\r\n",
        "from torchsummary import summary"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXMuQqVY_dKx"
      },
      "source": [
        "from torchvision import transforms\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "from tqdm.auto import tqdm\r\n",
        "from torchvision.utils import make_grid\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torchvision"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J552eanv_g8w"
      },
      "source": [
        "\r\n",
        "def show_tensor_images(image_tensor, num_images=2, size=(1, 28, 28) , switch = True):\r\n",
        "  image_shifted = image_tensor\r\n",
        "  #print(image_shifted)\r\n",
        "  image_unflat = image_shifted.detach().cpu().view(-1, *size)\r\n",
        "  #print(image_unflat)\r\n",
        "  image_grid = make_grid(image_unflat[:num_images], nrow=2 , normalize=False)\r\n",
        "  #print(image_grid)\r\n",
        "  if switch:\r\n",
        "    image_grid = image_grid * 255.0\r\n",
        "  plt.imshow(image_grid.permute(1, 2, 0).squeeze())\r\n",
        "  plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRJwbDgWovjU"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-wsPDIU9wlA"
      },
      "source": [
        "def crop(image, new_shape):\r\n",
        "  middle_height = image.shape[2] // 2\r\n",
        "  middle_width = image.shape[3] // 2\r\n",
        "  starting_height = middle_height - new_shape[2] // 2\r\n",
        "  final_height = starting_height + new_shape[2]\r\n",
        "  starting_width = middle_width - new_shape[3] // 2\r\n",
        "  final_width = starting_width + new_shape[3]\r\n",
        "  cropped_image = image[:, :, starting_height:final_height, starting_width:final_width]\r\n",
        "  return cropped_image"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5H8qDJ8LzEb"
      },
      "source": [
        "class Downsample(nn.Module):\r\n",
        "  def __init__(self , \r\n",
        "               in_channels , \r\n",
        "               use_norm = True , \r\n",
        "               use_dropout = False):\r\n",
        "    super(Downsample , self).__init__()\r\n",
        "\r\n",
        "    self.use_norm = use_norm\r\n",
        "    self.use_dropout = use_dropout\r\n",
        "\r\n",
        "    self.conv1 = nn.Conv2d(in_channels , in_channels * 2 , kernel_size=3 , padding=1)\r\n",
        "    self.conv2 = nn.Conv2d(in_channels * 2 , in_channels * 2 , kernel_size=3 , padding=1)\r\n",
        "    \r\n",
        "    self.activation = nn.ReLU(0.2)\r\n",
        "\r\n",
        "    self.maxpool = nn.MaxPool2d(kernel_size=2)\r\n",
        "\r\n",
        "\r\n",
        "    if self.use_norm:\r\n",
        "      self.norm = nn.InstanceNorm2d(in_channels * 2)\r\n",
        "\r\n",
        "    if self.use_dropout:\r\n",
        "      self.dropout = nn.Dropout()\r\n",
        "\r\n",
        "  def forward(self , x):\r\n",
        "    x = self.conv1(x)\r\n",
        "    if self.use_norm:\r\n",
        "      x = self.norm(x)\r\n",
        "    if self.use_dropout:\r\n",
        "      x = self.dropout(x)\r\n",
        "    x = self.activation(x)\r\n",
        "\r\n",
        "    x = self.conv2(x)\r\n",
        "    if self.use_norm:\r\n",
        "      x = self.norm(x)\r\n",
        "    if self.use_dropout:\r\n",
        "      x = self.dropout(x)\r\n",
        "    x = self.activation(x)\r\n",
        "\r\n",
        "    x = self.maxpool(x)\r\n",
        "    return x"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ki5JJFLuOZet"
      },
      "source": [
        "class Upsample(nn.Module):\r\n",
        "  def __init__(self , \r\n",
        "               in_channels , \r\n",
        "               use_norm = True , \r\n",
        "               use_dropout = False):\r\n",
        "    super(Upsample , self).__init__()\r\n",
        "\r\n",
        "    self.use_norm = use_norm\r\n",
        "    self.use_dropout = use_dropout\r\n",
        "\r\n",
        "    self.convT1 = nn.ConvTranspose2d(in_channels , in_channels , kernel_size=2 , stride=2 , padding=0)\r\n",
        "\r\n",
        "    self.conv1 = nn.Conv2d(in_channels   , in_channels // 2 , kernel_size=3 , padding=1)\r\n",
        "    self.conv2 = nn.Conv2d(in_channels  + in_channels//2, in_channels // 2, kernel_size=3 , padding=1)\r\n",
        "\r\n",
        "    self.lrelu = nn.LeakyReLU(0.2)\r\n",
        "\r\n",
        "    if self.use_norm:\r\n",
        "      self.norm = nn.InstanceNorm2d(in_channels * 2)\r\n",
        "    if self.use_dropout:\r\n",
        "      self.dropout = nn.Dropout()\r\n",
        "\r\n",
        "  def forward(self , x , x_skip_con):\r\n",
        "    #print(x.shape)\r\n",
        "    x = self.convT1(x)\r\n",
        "    #print(x.shape)\r\n",
        "    x = self.conv1(x)\r\n",
        "    if self.use_norm:\r\n",
        "      x = self.norm(x)\r\n",
        "    if self.use_dropout:\r\n",
        "      x = self.dropout(x)\r\n",
        "    x = self.lrelu(x)\r\n",
        "\r\n",
        "    x_skip_con = crop(x_skip_con , x.shape)\r\n",
        "\r\n",
        "    #print(x_skip_con.shape)\r\n",
        "    #print(x.shape)\r\n",
        "    x = torch.cat((x , x_skip_con) , dim=1)\r\n",
        "    #print(x.shape)\r\n",
        "    x = self.conv2(x)\r\n",
        "\r\n",
        "    if self.use_norm:\r\n",
        "      x = self.norm(x)\r\n",
        "    if self.use_dropout:\r\n",
        "      x = self.dropout(x)\r\n",
        "    x = self.lrelu(x)\r\n",
        "\r\n",
        "    return x\r\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgMXLTNYbD90"
      },
      "source": [
        "upsample = Upsample(3 , use_dropout=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1clSZ6WbJEg"
      },
      "source": [
        "x = torch.randn(2 , 2048 , 8 , 8)\r\n",
        "y = torch.randn(2 , 3 , 512 , 512)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Ct3cB9LbjNZ"
      },
      "source": [
        ""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpYTVymbbw64"
      },
      "source": [
        "class Feature_map_block(nn.Module):\r\n",
        "  def __init__(self , \r\n",
        "               in_channels , \r\n",
        "               out_channels):\r\n",
        "    super(Feature_map_block , self).__init__()\r\n",
        "\r\n",
        "    \r\n",
        "    self.conv = nn.Conv2d(in_channels , in_channels * 2 , kernel_size = 1 , stride = 1)\r\n",
        "    self.instance = nn.InstanceNorm2d(in_channels * 2)\r\n",
        "    self.lrelu = nn.ReLU()\r\n",
        "\r\n",
        "    self.instance1 = nn.InstanceNorm2d(out_channels)\r\n",
        "    self.conv1 = nn.Conv2d(in_channels * 2 , out_channels , kernel_size=1 ,stride=1)\r\n",
        "\r\n",
        "  def forward(self , x):\r\n",
        "    x = self.lrelu(self.instance(self.conv(x)))\r\n",
        "    x = self.lrelu(self.instance1(self.conv1(x)))\r\n",
        "    return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bjpsJ7cgb5x"
      },
      "source": [
        "fmb = Feature_map_block(3 , 32).to(device)\r\n",
        "summary(fmb , (3 , 512 , 512))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJTRuTfof8OY"
      },
      "source": [
        "###################################################"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJYvU_2bqLyI"
      },
      "source": [
        "class Encoder(nn.Module):\r\n",
        "  def __init__(self ,in_channels , out_channels , hidden_dim = 32 ):\r\n",
        "    super(Encoder , self).__init__()\r\n",
        "\r\n",
        "    self.conv1 = nn.Conv2d(in_channels , hidden_dim , kernel_size=2,  stride=2)\r\n",
        "    self.instance1 = nn.InstanceNorm2d(hidden_dim)\r\n",
        "    self.conv2 = nn.Conv2d(hidden_dim , hidden_dim  * 2 , kernel_size=2 , stride=2)\r\n",
        "    self.instance2 = nn.InstanceNorm2d(hidden_dim * 2)\r\n",
        "    self.conv3 = nn.Conv2d(hidden_dim * 2 , hidden_dim * 4 , kernel_size=2 , stride=2)\r\n",
        "    self.instance3 = nn.InstanceNorm2d(hidden_dim  * 4)\r\n",
        "    self.conv4 = nn.Conv2d(hidden_dim * 4 , hidden_dim * 8 , kernel_size=2 , stride=2)\r\n",
        "    self.instance4 = nn.InstanceNorm2d(hidden_dim * 8)\r\n",
        "    self.conv5 = nn.Conv2d(hidden_dim * 8 , hidden_dim * 16 , kernel_size=2 , stride=2)\r\n",
        "    self.instance5 = nn.InstanceNorm2d(hidden_dim * 16)\r\n",
        "    self.conv6 = nn.Conv2d(hidden_dim * 16 , hidden_dim * 32 , kernel_size=2 , stride=2)\r\n",
        "    self.instance6 = nn.InstanceNorm2d(hidden_dim * 32)\r\n",
        "\r\n",
        "    self.relu = nn.LeakyReLU(0.2)\r\n",
        "\r\n",
        "  def forward(self , x):\r\n",
        "    x = self.relu(self.instance1(self.conv1(x)))\r\n",
        "    x = self.relu(self.instance2(self.conv2(x)))\r\n",
        "    x = self.relu(self.instance3(self.conv3(x)))\r\n",
        "    x = self.relu(self.instance4(self.conv4(x)))\r\n",
        "    x = self.relu(self.instance5(self.conv5(x)))\r\n",
        "    x = self.relu(self.instance6(self.conv6(x)))\r\n",
        "    return x\r\n",
        "\r\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJJr1JTlpxw9"
      },
      "source": [
        "class Dual_direction_GAN(nn.Module):\r\n",
        "  def __init__(self , in_channels ,  out_channels , hidden_dim = 32):\r\n",
        "    super(Dual_direction_GAN , self).__init__()\r\n",
        "\r\n",
        "    self.upfeature = Feature_map_block(in_channels , hidden_dim)\r\n",
        "    self.downsample1 = Downsample(hidden_dim )\r\n",
        "    self.downsample2 = Downsample(hidden_dim * 2 )\r\n",
        "    self.downsample3 = Downsample(hidden_dim * 4 )\r\n",
        "    self.downsample4 = Downsample(hidden_dim * 8 )\r\n",
        "    self.downsample5 = Downsample(hidden_dim  * 16)\r\n",
        "    self.downsample6 = Downsample(hidden_dim * 32)\r\n",
        "\r\n",
        "    self.fmb = Feature_map_block(hidden_dim * 64 , hidden_dim * 32)\r\n",
        "    self.encoder = Encoder(in_channels , hidden_dim * 32 )\r\n",
        "\r\n",
        "    self.fmb1 = Feature_map_block(hidden_dim * 32 * 2 , hidden_dim * 32)\r\n",
        "\r\n",
        "    self.upsample1 = Upsample(hidden_dim * 32)\r\n",
        "    self.upsample2 = Upsample(hidden_dim * 16)\r\n",
        "    self.upsample3 = Upsample(hidden_dim * 8)\r\n",
        "    self.upsample4 = Upsample(hidden_dim * 4)\r\n",
        "    self.upsample5 = Upsample(hidden_dim * 2)\r\n",
        "    self.upsample6 = Upsample(hidden_dim)\r\n",
        "\r\n",
        "    self.last = Feature_map_block(hidden_dim //2  , out_channels)\r\n",
        "    self.sigmoid = nn.ReLU()\r\n",
        "\r\n",
        "  def forward(self , x , y):\r\n",
        "    x0 = self.upfeature(x)\r\n",
        "    x1 = self.downsample1(x0)\r\n",
        "    x2 = self.downsample2(x1)\r\n",
        "    x3 = self.downsample3(x2)\r\n",
        "    x4 = self.downsample4(x3)\r\n",
        "    x5 = self.downsample5(x4)\r\n",
        "    x6 = self.downsample6(x5)\r\n",
        "\r\n",
        "    x6 = self.fmb(x6)\r\n",
        "    y = self.encoder(y)\r\n",
        "\r\n",
        "    #print(x6.shape , y.shape)\r\n",
        "    x6 = torch.cat((x6 , y) ,dim = 1)\r\n",
        "    x6 = self.fmb1(x6)\r\n",
        "\r\n",
        "    #print(x6.shape)\r\n",
        "    \r\n",
        "    x7 = self.upsample1(x6 , x5)\r\n",
        "    #print(x7.shape)\r\n",
        "    x8 = self.upsample2(x7 , x4)\r\n",
        "    x9 = self.upsample3(x8 , x3)\r\n",
        "    x10 = self.upsample4(x9 , x2)\r\n",
        "    x11 = self.upsample5(x10 , x1)\r\n",
        "    x12 = self.upsample6(x11 , x0)\r\n",
        "\r\n",
        "    #print(x12.shape)\r\n",
        "\r\n",
        "    x = self.sigmoid(self.last(x12))\r\n",
        "    return x\r\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izZmzn6GrpWK"
      },
      "source": [
        "x = torch.randn(2 , 3 , 512 , 512 ).to(device)\r\n",
        "y = torch.randn(2 , 3 , 512 , 512 ).to(device)\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7Hh-XVDsll6"
      },
      "source": [
        "GAN = Dual_direction_GAN(3 , 3).to(device)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1TT-BbBsrff"
      },
      "source": [
        "z = GAN(x , y)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rEr9DpDAGhN"
      },
      "source": [
        "class Helper_1(nn.Module):\r\n",
        "  def __init__(self , in_channels , out_channels , kernel_size = (2 , 2) , stride = (2 , 2) , use_batch_norm = True , activation = 'lreu'):\r\n",
        "    super(Helper_1 , self).__init__()\r\n",
        "\r\n",
        "    self.use_batch_norm = use_batch_norm\r\n",
        "    self.conv1 = nn.Conv2d(in_channels , out_channels , kernel_size , stride)\r\n",
        "    self.batch_norm = nn.InstanceNorm2d(out_channels)\r\n",
        "    self.activation = activation\r\n",
        "    if self.activation == 'relu':\r\n",
        "      self.relu = nn.ReLU()\r\n",
        "    else :\r\n",
        "      self.relu = nn.LeakyReLU(0.2)\r\n",
        "\r\n",
        "  def forward(self , x):\r\n",
        "    #print(x.shape)\r\n",
        "    x = self.conv1(x)\r\n",
        "    x = self.batch_norm(x)\r\n",
        "    x = self.relu(x)\r\n",
        "    #print(x.shape)\r\n",
        "    return x"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYL-DLD2stmH"
      },
      "source": [
        "class Discriminator(nn.Module):\r\n",
        "  def __init__(self , in_channels , hidden_dim , out_channels):\r\n",
        "    super(Discriminator , self).__init__()\r\n",
        "\r\n",
        "    self.conv1 = Helper_1(in_channels , hidden_dim , use_batch_norm=False)\r\n",
        "    self.conv2 = Helper_1(hidden_dim , hidden_dim * 2 )\r\n",
        "    self.conv3 = Helper_1(hidden_dim * 2 , hidden_dim * 4)\r\n",
        "    self.conv4 = Helper_1(hidden_dim * 4 , hidden_dim * 8)\r\n",
        "    self.conv5 = Helper_1(hidden_dim * 8 , hidden_dim * 16)\r\n",
        "    self.conv6 = Helper_1(hidden_dim * 16 , hidden_dim * 32)\r\n",
        "    self.conv7 = Helper_1(hidden_dim * 32 , hidden_dim * 32)\r\n",
        "    self.conv8 = Helper_1(hidden_dim * 32 , hidden_dim * 32)\r\n",
        "    self.flatten = nn.Flatten()\r\n",
        "\r\n",
        "    self.relu = nn.LeakyReLU(0.2)\r\n",
        "    self.linear1 = nn.Linear(4096 , hidden_dim * 32)\r\n",
        "    self.batchnorm1 = nn.BatchNorm1d(hidden_dim * 32)\r\n",
        "    self.linear2 = nn.Linear(hidden_dim * 32 , hidden_dim * 8)\r\n",
        "    self.batchnorm2 = nn.BatchNorm1d(hidden_dim * 8)\r\n",
        "    self.linear3 = nn.Linear(hidden_dim * 8 , hidden_dim)\r\n",
        "    self.batchnorm3 = nn.BatchNorm1d(hidden_dim)\r\n",
        "    self.linear4 = nn.Linear(hidden_dim , out_channels)\r\n",
        "    self.sigmoid = nn.Sigmoid()\r\n",
        "\r\n",
        "\r\n",
        "  def forward(self , x):\r\n",
        "    x = self.conv1(x)\r\n",
        "    x = self.conv2(x)\r\n",
        "    x = self.conv3(x)\r\n",
        "    x = self.conv4(x)\r\n",
        "    x = self.conv5(x)\r\n",
        "    x = self.conv6(x)\r\n",
        "    x = self.conv7(x)\r\n",
        "    x = self.conv8(x)\r\n",
        "    x = self.flatten(x)\r\n",
        "    x = self.relu(self.linear1(x))\r\n",
        "    x = self.relu(self.linear2(x))\r\n",
        "    x = self.relu(self.linear3(x))\r\n",
        "    x = self.sigmoid(self.linear4(x))\r\n",
        "    return x"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PIoQO1Q_x0e"
      },
      "source": [
        "generator_x = Dual_direction_GAN(3 , 3).to(device)\r\n",
        "generator_y = Dual_direction_GAN(3 , 3).to(device)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdWwmO2C_9xr"
      },
      "source": [
        "\r\n",
        "discriminator_x = Discriminator(3 , 32 , 1).to(device)\r\n",
        "discriminator_y = Discriminator(3 , 32 , 1).to(device)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyUjjYdf_UXH"
      },
      "source": [
        "def weights_init(m):\r\n",
        "  if isinstance(m, nn.Conv2d) or isinstance(m, nn.ConvTranspose2d):\r\n",
        "    torch.nn.init.normal_(m.weight, 0.0, 0.02)\r\n",
        "  if isinstance(m, nn.BatchNorm2d):\r\n",
        "    torch.nn.init.normal_(m.weight, 0.0, 0.02)\r\n",
        "    torch.nn.init.constant_(m.bias, 0)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3fHlUnW_s0K"
      },
      "source": [
        "generator_x = generator_x.apply(weights_init)\r\n",
        "generator_y = generator_y.apply(weights_init)\r\n",
        "discriminator_x = discriminator_x.apply(weights_init)\r\n",
        "discriminator_y = discriminator_y.apply(weights_init)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M93hXGtOAWEO"
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss()\r\n",
        "l1_loss = nn.L1Loss()\r\n",
        "lambda_recon = 200\r\n",
        "mse_loss = nn.MSELoss()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8lNAsl2AlZH"
      },
      "source": [
        "n_epochs = 100\r\n",
        "input_dim = 3\r\n",
        "real_dim = 3\r\n",
        "display_step = 10\r\n",
        "batch_size = 2\r\n",
        "lr = 0.0002\r\n",
        "target_shape = 512\r\n",
        "betas = (0.5 , 0.999)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPaoYnV8Anm3"
      },
      "source": [
        "transform = transforms.Compose([ transforms.ToTensor(), ])\r\n",
        "\r\n",
        "dataset = torchvision.datasets.ImageFolder(\"/content/drive/MyDrive/Maps/maps/\", transform=transform)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPefLzRuA0RP"
      },
      "source": [
        "mean_generator_loss = 0\r\n",
        "mean_discriminator_loss = 0\r\n",
        "dataloader = DataLoader(dataset , batch_size = batch_size , shuffle=True)\r\n",
        "cur_step = 0"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYCzLmdKA-w-"
      },
      "source": [
        "opt_generator_y = torch.optim.Adam(generator_y.parameters() , lr=lr , betas=betas)\r\n",
        "opt_generator_x = torch.optim.Adam(generator_x.parameters() , lr = lr , betas = betas)\r\n",
        "opt_discriminator_x = torch.optim.Adam(discriminator_x.parameters() , lr = lr , betas=betas)\r\n",
        "opt_discriminator_y = torch.optim.Adam(discriminator_y.parameters() , lr = lr , betas=betas)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LKg2wWY3BEjl"
      },
      "source": [
        "\r\n",
        "def get_loss(fake , real  , criterion = criterion , l1_loss = l1_loss , lambda_recon = lambda_recon , switch = True):\r\n",
        "  gen_loss = criterion(fake , real)\r\n",
        "  l1_loss_ = l1_loss(fake , real)\r\n",
        "  if switch:\r\n",
        "    loss = gen_loss + lambda_recon *  l1_loss_\r\n",
        "  else:\r\n",
        "    loss = gen_loss \r\n",
        "  return loss"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFRhSzSMBGN2"
      },
      "source": [
        "for epoch in range(n_epochs):\r\n",
        "  for img , _ in tqdm(dataloader):\r\n",
        "    image_width = img.shape[3]\r\n",
        "    condition = img[: , : , : , :image_width//2]\r\n",
        "    condition = nn.functional.interpolate(condition , size = target_shape)\r\n",
        "    real = img[: , : , : , image_width//2:]\r\n",
        "    real = nn.functional.interpolate(real , size = target_shape)\r\n",
        "    cur_batch_size = len(condition)\r\n",
        "    real = real.to(device)\r\n",
        "    condition = condition.to(device)  \r\n",
        "\r\n",
        "    opt_generator_y.zero_grad()\r\n",
        "    Y_XY = generator_y(real , real)\r\n",
        "    Y_YY = generator_y(condition , real)\r\n",
        "\r\n",
        "    #loss_Y_XY = criterion(Y_XY , condition)\r\n",
        "    loss_Y_XY = get_loss(Y_XY , condition , switch=True)\r\n",
        "    #loss_Y_YY = criterion(Y_YY , condition)\r\n",
        "    loss_Y_YY = get_loss(Y_YY , condition , switch=True)\r\n",
        "    loss_Y = (loss_Y_XY + loss_Y_YY) /2\r\n",
        "\r\n",
        "\r\n",
        "    loss_Y.backward()\r\n",
        "    opt_generator_y.step()\r\n",
        "\r\n",
        "\r\n",
        "    opt_generator_x.zero_grad()\r\n",
        "    X_XX = generator_x(real , condition)\r\n",
        "    X_YX = generator_x(condition , condition)\r\n",
        "\r\n",
        "    #loss_X_XX = criterion(X_XX , real)\r\n",
        "    loss_X_XX = get_loss(X_XX , real , switch=True)\r\n",
        "    #loss_X_YX = criterion(X_YX , real)\r\n",
        "    loss_X_YX = get_loss(X_YX , real ,  switch=True)\r\n",
        "    loss_X = (loss_X_XX + loss_X_YX) /2\r\n",
        "    loss_X.backward()\r\n",
        "    opt_generator_x.step()\r\n",
        "\r\n",
        "\r\n",
        "    opt_discriminator_y.zero_grad()\r\n",
        "    with torch.no_grad():\r\n",
        "      disc_Y_XY = generator_y(real , real)\r\n",
        "      disc_Y_YY = generator_y(condition ,real)\r\n",
        "    disc_fake_y_pred_YX = discriminator_y(disc_Y_XY)\r\n",
        "    disc_loss_fake_pred_YX = criterion(disc_fake_y_pred_YX , torch.zeros_like(disc_fake_y_pred_YX))\r\n",
        "\r\n",
        "    disc_fake_y_pred_YY = discriminator_y(disc_Y_YY)\r\n",
        "    disc_loss_fake_pred_YY = criterion(disc_fake_y_pred_YY , torch.zeros_like(disc_fake_y_pred_YY))\r\n",
        "\r\n",
        "    disc_real_pred = discriminator_y(condition)\r\n",
        "    disc_real_pred_loss = criterion(disc_real_pred , torch.ones_like(disc_real_pred))\r\n",
        "\r\n",
        "    disc_y_loss = (disc_loss_fake_pred_YX + disc_loss_fake_pred_YY + disc_real_pred_loss) /3\r\n",
        "    #print(disc_y_loss)\r\n",
        "\r\n",
        "    disc_y_loss.backward()\r\n",
        "    opt_discriminator_y.step()\r\n",
        "\r\n",
        "    opt_discriminator_x.zero_grad()\r\n",
        "    with torch.no_grad():\r\n",
        "      disc_X_XX = generator_x(real , condition)\r\n",
        "      disc_X_YX_ = generator_x(condition , condition)\r\n",
        "    disc_fake_pred_XX = discriminator_x(disc_X_XX)\r\n",
        "    disc_loss_fake_pred_XX = criterion(disc_fake_pred_XX , torch.zeros_like(disc_fake_pred_XX))\r\n",
        "\r\n",
        "    disc_fake_pred_YX_ = discriminator_x(disc_X_YX_)\r\n",
        "    disc_loss_fake_pred_YX_ = criterion(disc_fake_pred_YX_ , torch.zeros_like(disc_fake_pred_YX_))\r\n",
        "\r\n",
        "    disc_x_real_pred = discriminator_x(real)\r\n",
        "    disc_x_real_loss = criterion(disc_x_real_pred , torch.ones_like(disc_x_real_pred))\r\n",
        "    disc_x_loss = (disc_loss_fake_pred_XX + disc_loss_fake_pred_YX_ + disc_x_real_loss) / 3\r\n",
        "    #print(disc_x_loss)\r\n",
        "    disc_x_loss.backward()\r\n",
        "    opt_discriminator_x.step()\r\n",
        "\r\n",
        "    disc_loss = (disc_x_loss + disc_y_loss)/2\r\n",
        "    gen_loss = (loss_X + loss_Y)/2\r\n",
        "\r\n",
        "    mean_discriminator_loss += disc_loss.item() / display_step\r\n",
        "    mean_generator_loss += gen_loss.item() / display_step\r\n",
        "\r\n",
        "    if cur_step % display_step == 0:\r\n",
        "      if cur_step > 0:\r\n",
        "        print(f\"Epoch {epoch}: Step {cur_step}: Generator loss: {mean_generator_loss}, Discriminator loss: {mean_discriminator_loss}\")\r\n",
        "      else:\r\n",
        "        print(\"Pretrained initial state\")\r\n",
        "      print('Y')\r\n",
        "      show_tensor_images(condition, size=(input_dim, target_shape, target_shape) , switch=False)\r\n",
        "      print('X')\r\n",
        "      show_tensor_images(real, size=(real_dim, target_shape, target_shape) , switch=False)\r\n",
        "      print('X --> Y')\r\n",
        "      show_tensor_images(Y_XY, size=(real_dim, target_shape, target_shape) , switch=False)\r\n",
        "      #plt.imshow(  Y_XY.permute(1, 2, 0))\r\n",
        "      print('Y --> Y')\r\n",
        "      show_tensor_images(Y_YY, size=(real_dim, target_shape, target_shape) , switch=False)\r\n",
        "      #plt.imshow(  Y_YY.permute(1, 2, 0))\r\n",
        "      print('X --> X')\r\n",
        "      show_tensor_images(X_XX, size=(real_dim, target_shape, target_shape) , switch=False)\r\n",
        "      print('Y --> X')\r\n",
        "      show_tensor_images(X_YX, size=(real_dim, target_shape, target_shape) , switch= False)\r\n",
        "      mean_generator_loss = 0\r\n",
        "      mean_discriminator_loss = 0\r\n",
        "    cur_step += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYmzmuMarHD8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}