{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Self_Adaptive_Sparse_Transform_GAN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXf1DETBR6RwU+ktxwvLzR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VedantDere0104/GANs/blob/main/Self_Adaptive_Sparse_Transform_GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClycW7ae_FEk"
      },
      "source": [
        "####"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04Gr0nMELs-b"
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBD89b3gspmA"
      },
      "source": [
        "class MLP(tf.keras.layers.Layer):\r\n",
        "  def __init__(self , n_filters , input_shape , output_shape , activation = 'relu'):\r\n",
        "    super(MLP , self).__init__()\r\n",
        "    self.convT = tf.keras.layers.Conv2DTranspose(filters=n_filters , kernel_size=4 , strides=2 , padding='valid' )\r\n",
        "    self.batch_norm = tf.keras.layers.BatchNormalization()\r\n",
        "    self.relu = tf.keras.layers.ReLU()\r\n",
        "    self.tanh = tf.keras.layers.Activation('tanh')\r\n",
        "    self.activation = activation\r\n",
        "\r\n",
        "  def call(self , x):\r\n",
        "    x = self.convT(x)\r\n",
        "    x = self.batch_norm(x)\r\n",
        "    if self.activation == 'relu':\r\n",
        "      x = self.relu(x)\r\n",
        "    elif self.activation == 'tanh':\r\n",
        "      x = self.tanh(x)\r\n",
        "    return x"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uv4htZdtqL5"
      },
      "source": [
        "class CSM(tf.keras.layers.Layer):\r\n",
        "  def __init__(self , n_filters, input_shape , output_shape):\r\n",
        "    super(CSM , self).__init__()\r\n",
        "\r\n",
        "    self.dense = tf.keras.layers.Dense(n_filters , activation='relu')\r\n",
        "  \r\n",
        "  def call(self , x):\r\n",
        "    x = self.dense(x)\r\n",
        "    return x"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UBE1pzf4uKu5"
      },
      "source": [
        "class PSM(tf.keras.layers.Layer):\r\n",
        "  def __init__(self , n_filters , input_shape , output_shape , use_conv = False):\r\n",
        "    super(PSM , self).__init__()\r\n",
        "\r\n",
        "    self.use_conv = use_conv\r\n",
        "\r\n",
        "    self.convT = tf.keras.layers.Conv2DTranspose(n_filters , 4 , 2 , padding='valid')\r\n",
        "    self.conv = tf.keras.layers.Conv2D(n_filters , 4 , 2 , padding='same')\r\n",
        "    self.relu = tf.keras.layers.ReLU()\r\n",
        "\r\n",
        "  def call(self , x):\r\n",
        "    if self.use_conv:\r\n",
        "      x = self.conv(x)\r\n",
        "    else:\r\n",
        "      x = self.convT(x)\r\n",
        "    \r\n",
        "    x = self.relu(x)\r\n",
        "    return x\r\n",
        "    "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-X6gsbGcu7u0"
      },
      "source": [
        "class Feature_Map_Recombination(tf.keras.layers.Layer):\r\n",
        "  def __init__(self , n_filters , input_shape , output_shape):\r\n",
        "    super(Feature_Map_Recombination , self).__init__()\r\n",
        "    \r\n",
        "    self.alpha = CSM(n_filters , input_shape , output_shape)\r\n",
        "    self.beta = PSM(n_filters , input_shape , output_shape)\r\n",
        "\r\n",
        "  def call(self , x):\r\n",
        "    alpha_ = tf.matmul(self.alpha , x)\r\n",
        "    beta_ = tf.matmul(self.beta , x)\r\n",
        "    x = alpha_ + beta_\r\n",
        "    return x"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjwfV2JTvzKC"
      },
      "source": [
        "class Repeating_layer(tf.keras.layers.Layer):\r\n",
        "  def __init__(self , n_filters , input_shape , output_shape):\r\n",
        "    super(Repeating_layer , self).__init__()\r\n",
        "\r\n",
        "    self.convT = tf.keras.layers.Conv2DTranspose(n_filters , 4 , 2 , padding='valid')\r\n",
        "    self.sastm = Feature_Map_Recombination(n_filters , input_shape , output_shape)\r\n",
        "    self.batch_norm = tf.keras.layers.BatchNormalization()\r\n",
        "    self.relu = tf.keras.layers.ReLU()\r\n",
        "\r\n",
        "  def call(self , x):\r\n",
        "    x = self.convT(x)\r\n",
        "    x = self.sastm(x)\r\n",
        "    x = self.batch_norm(x)\r\n",
        "    x = self.relu(x)\r\n",
        "    return x"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHTsLlHhwaOO"
      },
      "source": [
        "class GAN(tf.keras.layers.Layer):\r\n",
        "  def __init__(self , input_shape , output_shape):\r\n",
        "    super(GAN , self).__init__()\r\n",
        "    n_filters = 64\r\n",
        "    hidden_dim = 64\r\n",
        "\r\n",
        "    self.mlp = MLP(n_filters , input_shape , hidden_dim )\r\n",
        "    self.repeat = tf.keras.Sequential(\r\n",
        "        [\r\n",
        "         Repeating_layer(n_filters , hidden_dim , hidden_dim * 2) , \r\n",
        "         Repeating_layer(n_filters * 2 , hidden_dim * 2 , hidden_dim * 4) ,\r\n",
        "         Repeating_layer(n_filters * 4 , hidden_dim*4 , hidden_dim * 8 ) , \r\n",
        "         Repeating_layer(n_filters * 8 , hidden_dim * 8 , hidden_dim * 16) , \r\n",
        "         Repeating_layer(n_filters * 16 , hidden_dim * 16 , hidden_dim * 8) \r\n",
        "\r\n",
        "        ]\r\n",
        "    )\r\n",
        "\r\n",
        "    self.last_layer = MLP(3, hidden_dim * 8 , output_shape , activation='tanh')\r\n",
        "\r\n",
        "  def call(self , x):\r\n",
        "    x = self.mlp(x)\r\n",
        "    x = self.repeat(x)\r\n",
        "    x = self.last_layer(x)\r\n",
        "    return x\r\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jugxzOAP6ViE"
      },
      "source": [
        ""
      ],
      "execution_count": 17,
      "outputs": []
    }
  ]
}